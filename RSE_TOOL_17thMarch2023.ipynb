{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3AhQXqisqJhUZIxH7BfUQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaurav7004/RSE_TOOL/blob/main/RSE_TOOL_17thMarch2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y-KFBWnpcdJe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# ! pip install pandarallel\n",
        "# from pandarallel import pandarallel\n",
        "import json\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JcdH3PeNdMES"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pandarallel.initialize()"
      ],
      "metadata": {
        "id": "tsdvu58itpPJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv('Data1.csv')"
      ],
      "metadata": {
        "id": "j_AWweohegUD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data is the dictionary\n",
        "data = {}\n",
        "\n",
        "## Keys\n",
        "key = ''\n",
        "\n",
        "## values\n",
        "values = []\n",
        "\n",
        "## Open\n",
        "with open('Example1.RSE', \"r\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line.startswith('#'):\n",
        "            if key:\n",
        "                key = key.split(\"'\")[0]\n",
        "                key = key.split(\"\\t\")[0]\n",
        "                data[key] = [v for v in values if v and not v.startswith(\"'\")]\n",
        "            key = line.split(\"'\")[0]\n",
        "            key = key.split(\"\\t\")[0]\n",
        "            values = []\n",
        "        elif line.startswith(\"'\"):\n",
        "            pass\n",
        "        else:\n",
        "            line = line.split(\"'\")[0]\n",
        "            values.append(line.strip())\n",
        "\n",
        "# add last group\n",
        "if key:\n",
        "    data[key] = [v for v in values if v and not v.startswith(\"'\")]\n",
        "\n",
        "print(json.dumps(data, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCaBn0Ltw5Ac",
        "outputId": "1f1070d8-32a4-4ee3-843a-1ca31f21a173"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"#SAMPLING SUBSAMPLE2\": [],\n",
            "    \"#GROUP 2\": [\n",
            "        \"SEC   C sec\",\n",
            "        \"ST_GR C NEWVAR\"\n",
            "    ],\n",
            "    \"#FILTER 1\": [\n",
            "        \"AGE>=15\"\n",
            "    ],\n",
            "    \"#VARIABLE 3  \": [\n",
            "        \"POP\\tN  NEWVAR\",\n",
            "        \"LF\\tN  NEWVAR\",\n",
            "        \"WRK\\tN  NEWVAR\"\n",
            "    ],\n",
            "    \"#FILE Data1.csv  \": [],\n",
            "    \"#RENAME  5    \": [\n",
            "        \"STRMID C sec+st+strm+sstrm\",\n",
            "        \"SS     C ss\",\n",
            "        \"NSS    N  nss\",\n",
            "        \"NSC    N  nsc\",\n",
            "        \"MULT   N  mult\"\n",
            "    ],\n",
            "    \"#TRANSFORM 4  \": [\n",
            "        \"ST_GR=\\\"G1\\\"   in(ST,\\\"10,19,20,21\\\")\",\n",
            "        \"ST_GR=\\\"G2\\\"   in(ST,\\\"11,12,13,14,15,16,17,18\\\")\",\n",
            "        \"ST_GR=\\\"G3\\\"   Otherwise\",\n",
            "        \"POP=1\",\n",
            "        \"WRK=1  in(CWS,\\\"11,12,21,31,41,51,61,61,71,72\\\")\",\n",
            "        \"WRK=0  NOT in(CWS,\\\"11,12,21,31,41,51,61,61,71,72\\\")\",\n",
            "        \"LF=1      in(CWS,\\\"11,12,21,31,41,51,61,61,71,72,81\\\")\",\n",
            "        \"LF=0      Otherwise\"\n",
            "    ],\n",
            "    \"#EST_RSE 7\": [\n",
            "        \"S POP\",\n",
            "        \"E POP\",\n",
            "        \"R POP\",\n",
            "        \"E 100*LF/POP\",\n",
            "        \"R LF/POP\",\n",
            "        \"E 100*WRK/POP\",\n",
            "        \"R WRK/POP\"\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the text file for reading\n",
        "with open('Example1.RSE', 'r') as input_file:\n",
        "    # Read the contents of the text file\n",
        "    file_contents = input_file.read()\n",
        "\n",
        "# Split the file contents into lines\n",
        "lines = file_contents.split('\\n')\n",
        "\n",
        "# Initialize some variables to hold the generated Python code\n",
        "sampling_code = ''\n",
        "filter_code = ''\n",
        "variable_code = ''\n",
        "rename_code = ''\n",
        "transform_code = ''\n",
        "est_rse_code = ''\n",
        "\n",
        "# Loop through each line of the file contents and generate Python code\n",
        "for line in lines:\n",
        "    if line.startswith('#SAMPLING'):\n",
        "        if '\\t' in line:\n",
        "            _, sampling_scheme = line.split('\\t')\n",
        "        else:\n",
        "            _, sampling_scheme, _ = line.split()\n",
        "\n",
        "    elif line.startswith('#FILTER'):\n",
        "        for line in lines:\n",
        "            if line.startswith('#SAMPLING'):\n",
        "                # Generate code for the sampling scheme\n",
        "                _, sampling_scheme = line.split(maxsplit=1)\n",
        "                sampling_code = f'sampling_scheme = \"{sampling_scheme.strip()}\"'\n",
        "            elif line.startswith('#FILTER'):\n",
        "                # Extract the number of conditions from the line\n",
        "                num_conditions_match = re.search(r'\\d+', line)\n",
        "                if num_conditions_match:\n",
        "                    num_conditions = int(num_conditions_match.group())\n",
        "                    filter_conditions = [lines[i] for i in range(1, num_conditions+1)]\n",
        "                    filter_code = ' & '.join(filter_conditions)\n",
        "                else:\n",
        "                    filter_code = ''\n",
        "\n",
        "    elif line.startswith('#VARIABLE'):\n",
        "        # Generate code for the selected variables\n",
        "        values = line.split()\n",
        "        if len(values) == 2:\n",
        "            _, num_variables = values\n",
        "            variables = [lines[i].split() for i in range(1, int(num_variables)+1)]\n",
        "            variable_code = ', '.join([f'{var[1]} = {var[0]}' for var in variables])\n",
        "\n",
        "\n",
        "    elif line.startswith('#RENAME'):\n",
        "        # Generate code for renaming variables\n",
        "        parts = line.split('#')[0].strip().split()\n",
        "        if len(parts) > 0:\n",
        "            num_renames = parts[0]\n",
        "            renames = [lines[i].strip().split() for i in range(1, int(num_renames)+1)]\n",
        "            rename_code += '\\n' + '\\n'.join([f'{rename[0]} = {rename[1]}' for rename in renames])\n",
        "\n",
        "\n",
        "    elif line.startswith('#TRANSFORM'):\n",
        "        # Generate code for transforming variables\n",
        "        num_transforms = line.strip().split()[1]\n",
        "        transforms = [lines[i] for i in range(1, int(num_transforms)+1)]\n",
        "        transform_code = '\\n'.join(transforms)\n",
        "\n",
        "    elif line.startswith('#EST_RSE'):\n",
        "        # Generate code for generating columns\n",
        "        parts = line.split()\n",
        "        if len(parts) != 3:\n",
        "            continue  # Skip line\n",
        "\n",
        "        num_columns = parts[1]\n",
        "        columns = [lines[i].split()[0] for i in range(2, int(num_columns)+2)]\n",
        "        est_rse_code = '\\n'.join([f'{col} = {sampling_scheme}({col}, {filter_code})' for col in columns])\n",
        "        code_blocks.append(est_rse_code)\n",
        "\n",
        "\n",
        "\n",
        "# Write the generated Python code to a file\n",
        "with open('output.py', 'w') as output_file:\n",
        "    output_file.write(f'from sampling import {sampling_scheme}\\n\\n')\n",
        "    output_file.write(f'{sampling_code}\\n')\n",
        "    output_file.write(f'{filter_code}\\n')\n",
        "    output_file.write(f'{variable_code}\\n')\n",
        "    output_file.write(f'{rename_code}\\n')\n",
        "    output_file.write(f'{transform_code}\\n')\n",
        "    output_file.write(f'{est_rse_code}\\n')\n"
      ],
      "metadata": {
        "id": "vQ7UCmJBxG-c"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SAMPLING_(data, df):\n",
        "    for key, value in data.items():\n",
        "        pass\n",
        "\n",
        "def GROUP_(data, df):\n",
        "    for key, value in data.items():\n",
        "        ### To read the sampling method used\n",
        "        if str('SAMPLING').lower() in str(key).lower():\n",
        "            if str('SUBSAMPLE2').lower() in str(key).lower():\n",
        "                return str('SUBSAMPLE2')\n",
        "            elif str('SRSWR').lower() in str(key).lower():\n",
        "                pass\n",
        "            elif str('SRSWOR').lower() in str(key).lower():\n",
        "                pass\n",
        "\n",
        "def FILTER_(data, df):\n",
        "    for key, value in data.items():\n",
        "        ### To read the sampling method used\n",
        "        if str('FILTER').lower() in str(key).lower():\n",
        "            ### Replace logical AND '&&' with 'and'\n",
        "            if '&&' in value[0]:\n",
        "                return value[0].replace('&&', 'and')\n",
        "            ### Replace logical OR '||' with 'or'\n",
        "            elif '||' in value[0]:\n",
        "                return value[0].replace('||', 'or')\n",
        "            else:\n",
        "                return value[0]\n",
        "\n",
        "def FILE_(data):\n",
        "    for key, value in data.items():\n",
        "        ### To read the file used\n",
        "        if str('FILE').lower() in str(key).lower():\n",
        "            if key.strip().endswith('.xlsx') or key.strip().endswith('.csv'):\n",
        "                match = re.search(r'[A-Za-z0-9]+\\.xlsx|[A-Za-z0-9]+\\.csv', key)   \n",
        "                if match:\n",
        "                    file_name = match.group(0)\n",
        "                    return file_name\n",
        "                else:\n",
        "                    file_name = None\n",
        "                    return file_name\n",
        "                print(file_name)\n",
        "\n",
        "            # return file_name\n",
        "\n",
        "def RENAME_(data, df):\n",
        "    # create an empty dictionary to store the column names\n",
        "    column_dict = {}\n",
        "\n",
        "    for key, value in data.items():\n",
        "        ### To read the file used\n",
        "        if str('RENAME').lower() in str(key).lower():\n",
        "            # value = [elem for elem in value[0].split(' ') if elem.strip()]\n",
        "            # return value\n",
        "\n",
        "            for col in value:\n",
        "                col_split = col.split()\n",
        "\n",
        "                # print(col_split[0])\n",
        "\n",
        "                # extract the last element as the column name\n",
        "                col_name = col_split[-1]\n",
        "\n",
        "                new_col_name = col_split[0]\n",
        "\n",
        "                ### if there is a \"+\" sign in the last element, concatenate the columns\n",
        "                if \"+\" in col_name:\n",
        "                    col_concat = col_name.split(\"+\")\n",
        "                    col_concat = [i.upper() for i in col_concat]\n",
        "\n",
        "                    # concatenate the columns\n",
        "                    df[new_col_name] = df.loc[:, col_concat].apply(lambda x: ''.join(['0' + str(i) if i < 10 else str(i) for i in x]), axis=1)\n",
        "\n",
        "                else:\n",
        "                    col_name = col_name.upper()\n",
        "                    print(type(col_name))\n",
        "\n",
        "\n",
        "def NEWVARIABLE_(data, df):\n",
        "    for key, value in data.items():\n",
        "        ### To read the file used\n",
        "        if str('VARIABLE').lower() in str(key).lower():\n",
        "            value = [s.split()[0] for s in value]\n",
        "            \n",
        "            for name in value:\n",
        "                df[name] = 0\n",
        "\n",
        "\n",
        "def TRANSFORM_(data, df):\n",
        "    # Initialize empty arrays to store the values\n",
        "    Arr1 = []\n",
        "    Arr2 = []\n",
        "    Arr3 = []\n",
        "\n",
        "    for key, value in data.items():\n",
        "        ### To read the file used\n",
        "        if str('TRANSFORM').lower() in str(key).lower():\n",
        "            lines = '\\n'.join(value)\n",
        "            lines = lines.split(\"\\n\")\n",
        "\n",
        "            # Loop through the lines and extract the values\n",
        "            for line in lines:\n",
        "                line_values = line.split('=')  # split the line into values\n",
        "                var_name = line_values[0].strip()  # extract the variable name\n",
        "                var_value = line_values[1].strip().split()[0]  # extract the variable value\n",
        "                condition = 'None'  # initialize the condition to None\n",
        "\n",
        "                # Check if the line contains \"Otherwise\"\n",
        "                if \"Otherwise\" in line:\n",
        "                    condition = \"Otherwise\"\n",
        "\n",
        "                # Check if the variable value contains an \"in\" statement\n",
        "                if \"in\" in line:\n",
        "                    if \"NOT in\" in line:\n",
        "                        condition = line.split()[1] + ' ' + line.split()[2]\n",
        "                    else:\n",
        "                        condition = line.split()[1]\n",
        "\n",
        "                # Append the values to the arrays\n",
        "                Arr1.append(var_name)\n",
        "                Arr2.append(var_value)\n",
        "                Arr3.append(condition)\n",
        "\n",
        "    return Arr1, Arr2, Arr3\n",
        "        \n",
        "\n",
        "def EST_RSE_(data):\n",
        "    for key, value in data.items():\n",
        "        pass\n",
        "\n",
        "# print(FILE_(data))\n",
        "df = pd.read_csv(FILE_(data))\n",
        "df = df.rename(columns=lambda x: x.strip())\n",
        "\n",
        "NEWVARIABLE_(data, df)"
      ],
      "metadata": {
        "id": "JOeTfpj33fid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a971eaec-57df-4b0c-ac7e-30ed68722702"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-3fe66c382919>:131: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(FILE_(data))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns, df['POP']"
      ],
      "metadata": {
        "id": "_lTGE07ya3aO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0161fd34-4295-45c1-fc5b-2402df6965eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['SEC', 'ST', 'FSU', 'IDNO', 'SEG', 'SSS', 'SSU', 'STRM', 'SSTRM', 'SS',\n",
              "        'NSS', 'NSC', 'MULT', 'HH_SIZE', 'HHTYPE', 'RELG', 'SG', 'MHCE',\n",
              "        'DC_ALL', 'DC_ST', 'SRL', 'REL', 'SEX', 'MSEX', 'AGE', 'MARST',\n",
              "        'GEDU_LVL', 'PAS', 'PS_SS', 'CWS', 'ERN_SELF', 'ERN_REG', 'POP', 'LF',\n",
              "        'WRK'],\n",
              "       dtype='object'), 0         0\n",
              " 1         0\n",
              " 2         0\n",
              " 3         0\n",
              " 4         0\n",
              "          ..\n",
              " 109851    0\n",
              " 109852    0\n",
              " 109853    0\n",
              " 109854    0\n",
              " 109855    0\n",
              " Name: POP, Length: 109856, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input string\n",
        "input_str = '''ST_GR=\"G1\"   in(ST,\"10,19,20,21\")\n",
        "                  ST_GR=\"G2\"   in(ST,\"11,12,13,14,15,16,17,18\")\n",
        "                  ST_GR=\"G3\"   Otherwise\n",
        "                  POP=1\n",
        "                  WRK=1  in(CWS,\"11,12,21,31,41,51,61,61,71,72\")\n",
        "                  WRK=0  NOT in(CWS,\"11,12,21,31,41,51,61,61,71,72\")\n",
        "                  LF=1      in(CWS,\"11,12,21,31,41,51,61,61,71,72,81\")\n",
        "                  LF=0      Otherwise'''\n",
        "\n",
        "# Split the input string into lines\n",
        "lines = input_str.split('\\n')\n",
        "\n",
        "# Initialize empty arrays to store the values\n",
        "Arr1 = []\n",
        "Arr2 = []\n",
        "Arr3 = []\n",
        "\n",
        "# Loop through the lines and extract the values\n",
        "for line in lines:\n",
        "    line_values = line.split('=')  # split the line into values\n",
        "    var_name = line_values[0].strip()  # extract the variable name\n",
        "    var_value = line_values[1].strip().split()[0]  # extract the variable value\n",
        "    condition = 'None'  # initialize the condition to None\n",
        "\n",
        "    # Check if the line contains \"Otherwise\"\n",
        "    if \"Otherwise\" in line:\n",
        "        condition = \"Otherwise\"\n",
        "\n",
        "    # Check if the variable value contains an \"in\" statement\n",
        "    if \"in\" in line:\n",
        "        if \"NOT in\" in line:\n",
        "            condition = line.split()[1] + ' ' + line.split()[2]\n",
        "        else:\n",
        "            condition = line.split()[1]\n",
        "\n",
        "    # Append the values to the arrays\n",
        "    Arr1.append(var_name)\n",
        "    Arr2.append(var_value)\n",
        "    Arr3.append(condition)\n",
        "\n",
        "# Print the results\n",
        "# print(Arr1)\n",
        "# print(Arr2)\n",
        "# print(Arr3)\n",
        "\n",
        "Arr4 = []\n",
        "Arr5 = []\n",
        "\n",
        "for i in range(len(Arr3)):\n",
        "    if 'in' in Arr3[i]:\n",
        "        if 'NOT in' in Arr3[i]:\n",
        "            # pattern\n",
        "            pattern = r'^NOT\\s+in\\((\\w+),\\s*\"([^\"]+)\"\\)$'\n",
        "            # match\n",
        "            match = re.match(pattern, Arr3[i])\n",
        "\n",
        "            Arr4.append(match.group(1))\n",
        "            Arr5.append(match.group(2))\n",
        "            \n",
        "        else:\n",
        "            # pattern\n",
        "            pattern = r'^in\\((\\w+),\\s*\"([^\"]+)\"\\)$'\n",
        "            # match\n",
        "            match = re.match(pattern, Arr3[i])\n",
        "\n",
        "            Arr4.append(match.group(1))\n",
        "            Arr5.append(match.group(2))\n",
        "\n",
        "    elif 'Otherwise' in Arr3[i]:\n",
        "        # pattern\n",
        "        pattern = r'^Otherwise$'\n",
        "        # match\n",
        "        match = re.match(pattern, Arr3[i])\n",
        "\n",
        "        Arr4.append(match.group(0))\n",
        "        Arr5.append(None)\n",
        "\n",
        "    else:\n",
        "        Arr4.append(None)\n",
        "        Arr5.append(None)\n"
      ],
      "metadata": {
        "id": "NtMiw_fo7hvR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lst = []\n",
        "for value in Arr5:\n",
        "    if value is None:\n",
        "        lst.append(value)\n",
        "    else:\n",
        "        lst.append([int(x) for x in value.split(',')])\n",
        "\n",
        "Arr5 = lst"
      ],
      "metadata": {
        "id": "znnZMqYSu1Zd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(Arr1) - set(list(df.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpCHnWE634Lg",
        "outputId": "a8b50c06-354d-4aad-ddf3-e284f249c9e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ST_GR'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check for name mismatches and create new columns\n",
        "mismatched_names = set(Arr1) - set(df.columns)\n",
        "\n",
        "new_columns = {name: [0] * df.shape[0] for name in mismatched_names}\n",
        "df = df.assign(**new_columns)\n",
        "\n",
        "mismatched_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jb5zGh67zYH",
        "outputId": "844260fc-5471-447f-e5bf-d65c7ccf26f6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ST_GR'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(mismatched_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXXUwiS9yHBa",
        "outputId": "90681aa5-5c32-4efb-9938-17954da3ce93"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ST_GR']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Arr5, Arr4, Arr3, Arr2, Arr1, df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emidn8eF8G3U",
        "outputId": "0706a6b6-506f-4c5c-870f-2b86416c58c4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[10, 19, 20, 21],\n",
              "  [11, 12, 13, 14, 15, 16, 17, 18],\n",
              "  None,\n",
              "  None,\n",
              "  [11, 12, 21, 31, 41, 51, 61, 61, 71, 72],\n",
              "  [11, 12, 21, 31, 41, 51, 61, 61, 71, 72],\n",
              "  [11, 12, 21, 31, 41, 51, 61, 61, 71, 72, 81],\n",
              "  None],\n",
              " ['ST', 'ST', 'Otherwise', None, 'CWS', 'CWS', 'CWS', 'Otherwise'],\n",
              " ['in(ST,\"10,19,20,21\")',\n",
              "  'in(ST,\"11,12,13,14,15,16,17,18\")',\n",
              "  'Otherwise',\n",
              "  'None',\n",
              "  'in(CWS,\"11,12,21,31,41,51,61,61,71,72\")',\n",
              "  'NOT in(CWS,\"11,12,21,31,41,51,61,61,71,72\")',\n",
              "  'in(CWS,\"11,12,21,31,41,51,61,61,71,72,81\")',\n",
              "  'Otherwise'],\n",
              " ['\"G1\"', '\"G2\"', '\"G3\"', '1', '1', '0', '1', '0'],\n",
              " ['ST_GR', 'ST_GR', 'ST_GR', 'POP', 'WRK', 'WRK', 'LF', 'LF'],\n",
              " Index(['SEC', 'ST', 'FSU', 'IDNO', 'SEG', 'SSS', 'SSU', 'STRM', 'SSTRM', 'SS',\n",
              "        'NSS', 'NSC', 'MULT', 'HH_SIZE', 'HHTYPE', 'RELG', 'SG', 'MHCE',\n",
              "        'DC_ALL', 'DC_ST', 'SRL', 'REL', 'SEX', 'MSEX', 'AGE', 'MARST',\n",
              "        'GEDU_LVL', 'PAS', 'PS_SS', 'CWS', 'ERN_SELF', 'ERN_REG', 'POP', 'LF',\n",
              "        'WRK', 'ST_GR'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(Arr3)):\n",
        "\n",
        "    if 'in' in Arr3[i]:\n",
        "        curr_column = 0\n",
        "        lst_stack = []\n",
        "\n",
        "        ### For NOT in case \n",
        "        if 'NOT in' in Arr3[i]:\n",
        "            if Arr1[i] in list(df.columns):\n",
        "                df.loc[~df[Arr4[i]].isin(Arr5[i]), (Arr1[i])] = Arr2[i]\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "        ### For in case\n",
        "        else:\n",
        "            if Arr1[i] in list(df.columns) and Arr5[i] is not None:\n",
        "                # print(Arr1[i], Arr2[i], Arr4[i], Arr5[i])\n",
        "                print(i)\n",
        "                df.loc[df[Arr4[i]].isin(Arr5[i]), (Arr1[i])] = Arr2[i]\n",
        "                lst_stack.extend(Arr5[i])\n",
        "                curr_column = Arr4[i]\n",
        "                break\n",
        "\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "    elif 'Otherwise' in Arr3[i]:\n",
        "            if Arr1[i] in list(df.columns) and curr_column == True:\n",
        "                ### Otherwise case (11,12,13,14,15,16,17,18,10,19,20,21)\n",
        "                df.loc[~df[curr_column].isin(lst_stack), (Arr1[i])] = Arr2[i]\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "    else:\n",
        "        if Arr1[i] in list(df.columns):\n",
        "            # if Arr5[i] == None or Arr5[i] == 'None':\n",
        "            df.loc[df[Arr1[i]] == 0, Arr1[i]] = Arr2[i]\n",
        "\n",
        "    # print(lst_stack)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGRFczcPpCBU",
        "outputId": "915fa426-8e0e-431b-a09e-c61e3ef7425f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[''].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgrO93kD-Dd9",
        "outputId": "f69163d3-0819-4a15-9b43-acb6f858f008"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Arr5, Arr4, Arr3, Arr2, Arr1\n",
        "\n",
        "Arr4, Arr3, Arr1, Arr5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-cUzxIKrACo",
        "outputId": "8ccb2821-0370-4eb9-d9a3-db2a27ccc850"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['ST', 'ST', 'Otherwise', None, 'CWS', 'CWS', 'CWS', 'Otherwise'],\n",
              " ['in(ST,\"10,19,20,21\")',\n",
              "  'in(ST,\"11,12,13,14,15,16,17,18\")',\n",
              "  'Otherwise',\n",
              "  'None',\n",
              "  'in(CWS,\"11,12,21,31,41,51,61,61,71,72\")',\n",
              "  'NOT in(CWS,\"11,12,21,31,41,51,61,61,71,72\")',\n",
              "  'in(CWS,\"11,12,21,31,41,51,61,61,71,72,81\")',\n",
              "  'Otherwise'],\n",
              " ['ST_GR', 'ST_GR', 'ST_GR', 'POP', 'WRK', 'WRK', 'LF', 'LF'],\n",
              " [[10, 19, 20, 21],\n",
              "  [11, 12, 13, 14, 15, 16, 17, 18],\n",
              "  None,\n",
              "  None,\n",
              "  [11, 12, 21, 31, 41, 51, 61, 61, 71, 72],\n",
              "  [11, 12, 21, 31, 41, 51, 61, 61, 71, 72],\n",
              "  [11, 12, 21, 31, 41, 51, 61, 61, 71, 72, 81],\n",
              "  None])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for name mismatches and create new columns\n",
        "mismatched_names = set(Arr1) - set(df.columns)\n",
        "new_columns = {name: [0] * df.shape[0] for name in mismatched_names}\n",
        "df = df.assign(**new_columns)\n",
        "\n",
        "for i in range(len(Arr1)):\n",
        "    if Arr3[i] == 'in':\n",
        "        if isinstance(Arr5[i], int):\n",
        "            flattened_list = [Arr5[i]]\n",
        "        else:\n",
        "            flattened_list = [item for sublist in Arr5[i] for item in sublist] if (isinstance(Arr5[i], list) or isinstance(Arr5[i], tuple)) else [Arr5[i]]\n",
        "        df.loc[df[Arr4[i]].isin(flattened_list), (Arr1[i])] = Arr2[i]\n",
        "    elif Arr3[i] == 'NOT in':\n",
        "        if isinstance(Arr5[i], int):\n",
        "            flattened_list = [Arr5[i]]\n",
        "        else:\n",
        "            flattened_list = [item for sublist in Arr5[i] for item in sublist] if (isinstance(Arr5[i], list) or isinstance(Arr5[i], tuple)) else [Arr5[i]]\n",
        "        df.loc[~df[Arr4[i]].isin(flattened_list), (Arr1[i])] = 0\n"
      ],
      "metadata": {
        "id": "AONL8bkl9RZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ST_GR'].unique()"
      ],
      "metadata": {
        "id": "mCBMeJVNRNM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "zfpuZ4HUDNgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ldsdsist(set(Arr1)), Arr1, Arr2, Arr4, Arr5\n",
        "\n",
        "# # check for name mismatches and create new columns\n",
        "# mismatched_names = set(Arr1) - set(list(df.columns))\n",
        "# new_columns = {name: [0]*df.shape[0] for name in mismatched_names}\n",
        "# df = df.assign(**new_columns)\n",
        "# df.columns\n",
        "\n",
        "# for k, v in new_columns.items():\n",
        "#     print(k)\n",
        "#     df.loc[df[new_columns].isin([5, 6]), ('newVar1')] = df['    ERN_REG'] + df['   ERN_SELF']\n",
        "#     df.loc[~df['  GEDU_LVL'].isin([5, 6]), ('newVar1')] = 0"
      ],
      "metadata": {
        "id": "CRyPUnRls5Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_columns)"
      ],
      "metadata": {
        "id": "BAXH8kzSuvBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pdt2CoX90Lqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# df['newVar1'] = pd.Series([])\n",
        "# df.loc[df['  GEDU_LVL'].isin([5, 6]), ('newVar1')] = df['    ERN_REG'] + df['   ERN_SELF']\n",
        "# df.loc[~df['  GEDU_LVL'].isin([5, 6]), ('newVar1')] = 0"
      ],
      "metadata": {
        "id": "1EGpbbKnuRSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# input string\n",
        "string = 'NOT in(CWS,\"11,12,21,31,41,51,61,61,71,72\")'\n",
        "\n",
        "# pattern\n",
        "pattern = r'^NOT\\s+in\\((\\w+),\\s*\"([^\"]+)\"\\)$'\n",
        "\n",
        "# match\n",
        "match = re.match(pattern, string)\n",
        "\n",
        "print(match.group(1), type(match.group(2)))\n",
        "\n",
        "# extract groups\n",
        "if match:\n",
        "    cws = match.group(1)\n",
        "    integers = match.group(2)\n",
        "    integers_list = integers.split(',')\n",
        "    integers_set = set(integers_list)\n",
        "    print(f\"CWS: {cws}, Integers: {integers_set}\")\n",
        "else:\n",
        "    print(\"No match found.\")\n",
        "\n",
        "\n",
        "# convert integers to set of integers\n",
        "integers_set = set(map(int, integers_list))\n",
        "print(f\"CWS: {cws}, Integers: {integers_set}\")\n",
        "integers_set"
      ],
      "metadata": {
        "id": "LaaUDfcLNUeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tbG8D-iexHRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Reading and filtering column names\n",
        "df = pd.read_csv(FILE_(data))\n",
        "df = df.rename(columns=lambda x: x.strip())\n",
        "\n",
        "# print(NEWVARIABLE_(data, df)[0])\n",
        "\n",
        "for col in RENAME_(data, df):\n",
        "    col = [elem for elem in col.split(' ') if elem.strip()]\n",
        "    \n",
        "    # df[col[0]] = df[]\n",
        "\n",
        "    col_search = col[2].split('+')\n",
        "\n",
        "    # print(col_search)\n",
        "\n",
        "    for txt in col_search:\n",
        "        if txt in df.columns.str.lower():\n",
        "            pass\n",
        "            \n",
        "        # else:\n",
        "        #     print('No')\n",
        "\n",
        "    # print(col[2].split('+'))\n",
        "\n",
        "# df.query(FILTER_(data))\n",
        "\n",
        "# df = pd.read_csv(FILE_(data))\n",
        "# df.head(2)"
      ],
      "metadata": {
        "id": "88myB1h9GWvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6rK2PcSG9MCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2SGqYyRI8l3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## read the RSE file and extract the lines from it\n",
        "# with open('Example1.RSE') as f:\n",
        "\n",
        "#     ## Reading each line of the file \n",
        "#     lines = f.readlines()\n",
        "\n",
        "# ## To generate keys of the dictionary \n",
        "# keys = []\n",
        "\n",
        "# for line in lines:\n",
        "#     # print(line)\n",
        "#     line = line.strip()\n",
        "\n",
        "#     if line.startswith(\"#\"):\n",
        "\n",
        "#         quote_index = line.find(\"'\") \n",
        "#         if quote_index != -1:\n",
        "#             key = line[1:quote_index].split()\n",
        "\n",
        "#             # Check if the line is empty\n",
        "#             if not line:\n",
        "#                 # Empty line found, break out of the loop\n",
        "#                 break\n",
        "\n",
        "#             if key not in keys:\n",
        "#                 keys.append(key)\n",
        "\n",
        "# print(keys)"
      ],
      "metadata": {
        "id": "tBsptR5t2jro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### renaming the variables\n",
        "### **********************\n",
        "\n",
        "# rename the columns using a dictionary\n",
        "new_columns = {\n",
        "    'FSU': 'fsu',\n",
        "    'NS_SSS': 'NSS'\n",
        "}\n",
        "\n",
        "df = df.rename(columns=new_columns)\n",
        "\n",
        "df['STRMID'] = df['SEC'].apply(lambda x: f'0{x}' if x < 10 else str(x)) + \\\n",
        "                df['AST'].apply(lambda x: f'0{x}' if x < 10 else str(x)) + \\\n",
        "                 df[' STRM'].apply(lambda x: f'0{x}' if x < 10 else str(x)) + \\\n",
        "                  df['  SSTRM'].apply(lambda x: f'0{x}' if x < 10 else str(x))\n",
        "\n",
        "df[' SSU'] = df[' FSU'].astype(str) + df[' IDNO'].apply(lambda x: f'0{x}' if x < 10 else str(x))"
      ],
      "metadata": {
        "id": "-NL84AeLaLgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[' SSU']"
      ],
      "metadata": {
        "id": "G-lLPLS_g0Jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age = df['  AGE']\n",
        "\n",
        "# Function to calculate the right age group\n",
        "def get_age_group(age):\n",
        "    if age < 5:\n",
        "        return \"01\"\n",
        "    elif age >= 5 and age < 10:\n",
        "        return \"02\"\n",
        "    elif age >= 10 and age < 20:\n",
        "        return \"03\"\n",
        "    elif age >= 20 and age < 60:\n",
        "        return \"04\"\n",
        "    elif age >= 60:\n",
        "        return \"05\"\n",
        "    else:\n",
        "        return \"00\"\n",
        "\n",
        "# Apply the get_age_group function to each row in the \"age\" column in parallel\n",
        "df['AGE_GROUP'] = df['  AGE'].parallel_apply(get_age_group)\n"
      ],
      "metadata": {
        "id": "N8ZBvrnaqjTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Age group with right age\n",
        "def get_result(df):\n",
        "    age = df['  AGE']\n",
        "    ageGrp = df['AGE_GROUP']\n",
        "\n",
        "    if ageGrp == \"01\" and age < 5:\n",
        "        return \"01\"\n",
        "    elif ageGrp == \"02\" and age >= 5 and age < 10:\n",
        "        return \"02\"\n",
        "    elif ageGrp == \"03\" and age >= 10 and age < 20:\n",
        "        return \"03\"\n",
        "    elif ageGrp == \"04\" and age >= 20 and age < 60:\n",
        "        return \"04\"\n",
        "    elif ageGrp == \"05\" and age>=60:\n",
        "        return \"00\"\n",
        "    else:\n",
        "        return \"00\"\n",
        "\n",
        "df['AGE_GROUP'] = df.parallel_apply(get_result, axis=1)"
      ],
      "metadata": {
        "id": "OArj2-7cavaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "PYg1nU-htl-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Y1_(df):\n",
        "    df['newVar1'] = pd.Series([])\n",
        "    df.loc[df['  GEDU_LVL'].isin([5, 6]), ('newVar1')] = df['    ERN_REG'] + df['   ERN_SELF']\n",
        "    df.loc[~df['  GEDU_LVL'].isin([5, 6]), ('newVar1')] = 0\n",
        "\n",
        "def Y2_(df):\n",
        "    df['newVar2'] = pd.Series([])\n",
        "    df.loc[df['  GEDU_LVL'].isin([7, 8, 9]), ('newVar2')] = df['    ERN_REG'] + df['   ERN_SELF']\n",
        "    df.loc[~df['  GEDU_LVL'].isin([7, 8, 9]), ('newVar2')] = 0\n",
        "\n",
        "def Y3_(df):\n",
        "    df['newVar3'] = pd.Series([])\n",
        "    df.loc[df['  GEDU_LVL'].isin([5, 6, 7, 8, 9]), ('newVar3')] = df['    ERN_REG'] + df['   ERN_SELF']\n",
        "    df.loc[~df['  GEDU_LVL'].isin([5, 6, 7, 8, 9]), ('newVar3')] = 0\n",
        "\n",
        "def Y4_(df):\n",
        "    df['newVar4'] = pd.Series([])\n",
        "    df.loc[df['   ACWS'].isin([11,12,21,31,41,51,61,61,71,72]), ('newVar4')] = 1\n",
        "    df.loc[~df['   ACWS'].isin([11,12,21,31,41,51,61,61,71,72]), ('newVar4')] = 0\n",
        "\n",
        "def Y5_(df):\n",
        "    df['newVar5'] = pd.Series([])\n",
        "    df.loc[df['   ACWS'].isin([11,12,21,31,41,51,61,61,71,72,81]), ('newVar5')] = 1\n",
        "    df.loc[~df['   ACWS'].isin([11,12,21,31,41,51,61,61,71,72,81]), ('newVar5')] = 0\n",
        "\n",
        "def Y6_(df):\n",
        "    df['newVar6'] = 1"
      ],
      "metadata": {
        "id": "SNjm9Ox2QDto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y1_(df), Y2_(df), Y3_(df), Y4_(df), Y5_(df), Y6_(df)"
      ],
      "metadata": {
        "id": "rmEHB_4CzxLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Example-2: Defining another variable\n",
        "\n",
        "# print(\"select number of variables : \")\n",
        "\n",
        "# n_var = int(input())\n",
        "\n",
        "# ### creating no. of n_var\n",
        "# for i in range(1, n_var+1):\n",
        "#     # df['Y' + str(i)] = pd.Series([])\n",
        "#     df['X' + str(i)] = pd.Series([])\n",
        "\n",
        "#     if i == 1:\n",
        "#         df.loc[df['  GEDU_LVL'].isin([5, 6]), ('X' + str(i))] = df['    ERN_REG'] + df['   ERN_SELF']\n",
        "#         df.loc[~df['  GEDU_LVL'].isin([5, 6]), ('X' + str(i))] = 0\n",
        "#     elif i == 2:\n",
        "#         df.loc[df['  GEDU_LVL'].isin([7, 8, 9]), ('X' + str(i))] = df['    ERN_REG'] + df['   ERN_SELF']\n",
        "#         df.loc[~df['  GEDU_LVL'].isin([5, 6]), ('X' + str(i))] = 0\n",
        "#     elif i == 3:\n",
        "#         df.loc[df['  GEDU_LVL'].isin([5, 6, 7, 8, 9]), ('X' + str(i))] = df['    ERN_REG'] + df['   ERN_SELF']\n",
        "#         df.loc[~df['  GEDU_LVL'].isin([5, 6]), ('X' + str(i))] = 0\n",
        "    "
      ],
      "metadata": {
        "id": "UitiISSvgLqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['newVar3'].unique()"
      ],
      "metadata": {
        "id": "cdqxWKQrsLdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Transform the variables\n",
        "\n"
      ],
      "metadata": {
        "id": "QiohuFf6ELDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dW-UoIT5ELGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DHIS2AU0-LWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gjinDDBkELJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F5s_WheCELMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wWPpzCam-K92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zPZZ1NDtELPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('GROUP SEC ST AGE_Group.csv')"
      ],
      "metadata": {
        "id": "0CFPzLejegdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sutqWwv5k4Dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "ShQKtGWQeggE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YWM1BPKbegjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "glg1BRKWsIO3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}